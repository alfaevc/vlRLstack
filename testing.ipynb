{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n"
     ]
    }
   ],
   "source": [
    "from gym.envs.mujoco import HalfCheetahEnv\n",
    "from gym.envs.box2d import CarRacing\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n",
    "from rlkit.envs.wrappers import NormalizedBoxEnv\n",
    "from rlkit.launchers.launcher_util import setup_logger\n",
    "from rlkit.samplers.data_collector import MdpPathCollector\n",
    "from rlkit.torch.sac.policies import (\n",
    "    TanhGaussianPolicy,\n",
    "    MakeDeterministic,\n",
    "    TanhCNNGaussianPolicy,\n",
    "    GaussianCNNPolicy,\n",
    ")\n",
    "from rlkit.torch.sac.sac import SACTrainer\n",
    "from rlkit.torch.networks import ConcatMlp, PretrainedCNN, CNN\n",
    "from rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "ptu.set_gpu_mode(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dir(models))\n",
    "# out = torch.load(\n",
    "#     \"data/name-of-experiment/name-of-experiment_2021_11_17_18_49_42_0000--s-0/params.pkl\"\n",
    "# )\n",
    "# out.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fk u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant = dict(\n",
    "    algorithm=\"SAC\",\n",
    "    version=\"normal\",\n",
    "    layer_size=256,\n",
    "    replay_buffer_size=int(2e4),\n",
    "    algorithm_kwargs=dict(\n",
    "        num_epochs=300,\n",
    "        num_eval_steps_per_epoch=500,\n",
    "        num_trains_per_train_loop=100,\n",
    "        num_expl_steps_per_train_loop=100,\n",
    "        min_num_steps_before_training=100,\n",
    "        max_path_length=1000,\n",
    "        batch_size=16,\n",
    "    ),\n",
    "    trainer_kwargs=dict(\n",
    "        discount=0.99,\n",
    "        soft_target_tau=5e-3,\n",
    "        target_update_period=1,\n",
    "        policy_lr=3e-4,\n",
    "        qf_lr=3e-4,\n",
    "        reward_scale=1,\n",
    "        use_automatic_entropy_tuning=True,\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztan/miniconda3/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "expl_env = NormalizedBoxEnv(CarRacing())\n",
    "eval_env = NormalizedBoxEnv(CarRacing())\n",
    "obs_dim = expl_env.observation_space.low.size\n",
    "action_dim = eval_env.action_space.low.size\n",
    "M = variant[\"layer_size\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"size\" will return the desired product of dimensions\n",
    "\n",
    "(\n",
    "    input_width,\n",
    "    input_height,\n",
    "    input_channels,\n",
    ") = expl_env.observation_space.shape  # channel last!!!\n",
    "qf1 = PretrainedCNN(\n",
    "    input_width,\n",
    "    input_height,\n",
    "    input_channels,\n",
    "    output_size=1,\n",
    "    hidden_sizes=[128, 64],  # this is the hidden sizes of FC layers after the CNN\n",
    "    added_fc_input_size=action_dim,  # layer used to merge image output and action input\n",
    "    batch_norm_fc=False,\n",
    "    init_w=1e-4,\n",
    "    # hidden_init=nn.init.xavier_uniform_,\n",
    "    # hidden_activation=nn.ReLU(),\n",
    "    # output_activation=identity,\n",
    "    output_conv_channels=False,\n",
    "    model_architecture=models.efficientnet_b0,\n",
    "    model_pretrained=True,\n",
    "    model_freeze=False,\n",
    ")\n",
    "qf2 = PretrainedCNN(\n",
    "    input_width,\n",
    "    input_height,\n",
    "    input_channels,\n",
    "    output_size=1,\n",
    "    hidden_sizes=[128, 64],  # this is the hidden sizes of FC layers after the CNN\n",
    "    added_fc_input_size=action_dim,  # layer used to merge image output and action input\n",
    "    batch_norm_fc=False,\n",
    "    init_w=1e-4,\n",
    "    # hidden_init=nn.init.xavier_uniform_,\n",
    "    # hidden_activation=nn.ReLU(),\n",
    "    # output_activation=identity,\n",
    "    output_conv_channels=False,\n",
    "    model_architecture=models.efficientnet_b0,\n",
    "    model_pretrained=True,\n",
    "    model_freeze=False,\n",
    ")\n",
    "target_qf1 = PretrainedCNN(\n",
    "    input_width,\n",
    "    input_height,\n",
    "    input_channels,\n",
    "    output_size=1,\n",
    "    hidden_sizes=[128, 64],  # this is the hidden sizes of FC layers after the CNN\n",
    "    added_fc_input_size=action_dim,  # layer used to merge image output and action input\n",
    "    batch_norm_fc=False,\n",
    "    init_w=1e-4,\n",
    "    # hidden_init=nn.init.xavier_uniform_,\n",
    "    # hidden_activation=nn.ReLU(),\n",
    "    # output_activation=identity,\n",
    "    output_conv_channels=False,\n",
    "    model_architecture=models.efficientnet_b0,\n",
    "    model_pretrained=True,\n",
    "    model_freeze=False,\n",
    ")\n",
    "target_qf2 = PretrainedCNN(\n",
    "    input_width,\n",
    "    input_height,\n",
    "    input_channels,\n",
    "    output_size=1,\n",
    "    hidden_sizes=[128, 64],  # this is the hidden sizes of FC layers after the CNN\n",
    "    added_fc_input_size=action_dim,  # layer used to merge image output and action input\n",
    "    batch_norm_fc=False,\n",
    "    init_w=1e-4,\n",
    "    # hidden_init=nn.init.xavier_uniform_,\n",
    "    # hidden_activation=nn.ReLU(),\n",
    "    # output_activation=identity,\n",
    "    output_conv_channels=False,\n",
    "    model_architecture=models.efficientnet_b0,\n",
    "    model_pretrained=True,\n",
    "    model_freeze=False,\n",
    ")\n",
    "policy = GaussianCNNPolicy(\n",
    "    hidden_sizes=[128, 64],  # hidden size of FC after CNN; it uses \"return_last_activations\" to skip the last FC\n",
    "    obs_dim=obs_dim,\n",
    "    action_dim=action_dim,\n",
    "    std=None,\n",
    "    init_w=1e-3,\n",
    "    min_log_std=-20,\n",
    "    max_log_std=2,\n",
    "    std_architecture=\"shared\",\n",
    "    **{\n",
    "        \"input_width\": input_width,\n",
    "        \"input_height\": input_height,\n",
    "        \"input_channels\": input_channels,\n",
    "        \"kernel_sizes\": [5, 5, 5],\n",
    "        \"n_channels\": [32, 64, 128],\n",
    "        \"strides\": [1] * 3,\n",
    "        \"paddings\": [\"same\"] * 3,\n",
    "    },\n",
    ")\n",
    "\n",
    "# self.conv_output_flat_size: 1280 is the CNN output (effnet for example!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = MakeDeterministic(policy)\n",
    "eval_path_collector = MdpPathCollector(eval_env, eval_policy,)\n",
    "expl_path_collector = MdpPathCollector(expl_env, policy,)\n",
    "replay_buffer = EnvReplayBuffer(variant[\"replay_buffer_size\"], expl_env,)\n",
    "\n",
    "trainer = SACTrainer(\n",
    "        env=eval_env,\n",
    "        policy=policy,\n",
    "        qf1=qf1,\n",
    "        qf2=qf2,\n",
    "        target_qf1=target_qf1,\n",
    "        target_qf2=target_qf2,\n",
    "        **variant[\"trainer_kwargs\"]\n",
    "    )\n",
    "algorithm = TorchBatchRLAlgorithm(\n",
    "    trainer=trainer,\n",
    "    exploration_env=expl_env,\n",
    "    evaluation_env=eval_env,\n",
    "    exploration_data_collector=expl_path_collector,\n",
    "    evaluation_data_collector=eval_path_collector,\n",
    "    replay_buffer=replay_buffer,\n",
    "    **variant[\"algorithm_kwargs\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-17 22:33:08.701349 EST | Variant:\n",
      "2021-11-17 22:33:08.701856 EST | {\n",
      "  \"algorithm\": \"SAC\",\n",
      "  \"version\": \"normal\",\n",
      "  \"layer_size\": 256,\n",
      "  \"replay_buffer_size\": 20000,\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"num_epochs\": 300,\n",
      "    \"num_eval_steps_per_epoch\": 500,\n",
      "    \"num_trains_per_train_loop\": 100,\n",
      "    \"num_expl_steps_per_train_loop\": 100,\n",
      "    \"min_num_steps_before_training\": 100,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"batch_size\": 16\n",
      "  },\n",
      "  \"trainer_kwargs\": {\n",
      "    \"discount\": 0.99,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"policy_lr\": 0.0003,\n",
      "    \"qf_lr\": 0.0003,\n",
      "    \"reward_scale\": 1,\n",
      "    \"use_automatic_entropy_tuning\": true\n",
      "  }\n",
      "}\n",
      "Track generation: 1192..1504 -> 312-tiles track\n",
      "retry to generate track (normal if there are not manyinstances of this message)\n",
      "Track generation: 1083..1358 -> 275-tiles track\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to establish dbus connection"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1096..1382 -> 286-tiles track\n",
      "Track generation: 1160..1454 -> 294-tiles track\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "start (27648) + length (3) exceeds dimension size (27648).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_57555/2834512982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msetup_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"carRace_testing\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0malgorithm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/rlkit-master/rlkit/core/batch_rl_algorithm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffline_rl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/rlkit-master/rlkit/core/batch_rl_algorithm.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_trains_per_train_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/rlkit-master/rlkit/torch/torch_rl_algorithm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, np_batch)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_train_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_to_pytorch_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/rlkit-master/rlkit/torch/sac/sac.py\u001b[0m in \u001b[0;36mtrain_from_torch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_from_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblank_stamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         losses, stats = self.compute_loss(\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mskip_statistics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_need_to_update_eval_statistics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/rlkit-master/rlkit/torch/sac/sac.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, batch, skip_statistics)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         q_new_actions = torch.min(\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_obs_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_obs_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/rlkit-master/rlkit/torch/networks/pretrained_cnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, return_last_activations)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_fc_input_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             extra_fc_input = input.narrow(\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_input_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madded_fc_input_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: start (27648) + length (3) exceeds dimension size (27648)."
     ]
    }
   ],
   "source": [
    "setup_logger(\"carRace_testing\", variant=variant)\n",
    "algorithm.to(ptu.device)\n",
    "algorithm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trial = (np.random.randn(1,96,96,3), np.random.randn(1,3))\n",
    "torch.from_numpy(*trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No personal conf_private.py found.\n",
      "doodad not detected\n",
      "2021-11-17 22:38:53.977657 EST | Variant:\n",
      "2021-11-17 22:38:53.978159 EST | {\n",
      "  \"algorithm\": \"SAC\",\n",
      "  \"version\": \"normal\",\n",
      "  \"layer_size\": 256,\n",
      "  \"replay_buffer_size\": 20000,\n",
      "  \"algorithm_kwargs\": {\n",
      "    \"num_epochs\": 1,\n",
      "    \"num_eval_steps_per_epoch\": 500,\n",
      "    \"num_trains_per_train_loop\": 100,\n",
      "    \"num_expl_steps_per_train_loop\": 100,\n",
      "    \"min_num_steps_before_training\": 100,\n",
      "    \"max_path_length\": 1000,\n",
      "    \"batch_size\": 16\n",
      "  },\n",
      "  \"trainer_kwargs\": {\n",
      "    \"discount\": 0.99,\n",
      "    \"soft_target_tau\": 0.005,\n",
      "    \"target_update_period\": 1,\n",
      "    \"policy_lr\": 0.0003,\n",
      "    \"qf_lr\": 0.0003,\n",
      "    \"reward_scale\": 1,\n",
      "    \"use_automatic_entropy_tuning\": true\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztan/miniconda3/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "o_for_agent (17,)\n",
      "2021-11-17 22:38:57.152063 EST | [name-of-experiment_2021_11_17_22_38_53_0000--s-0] Epoch 0 finished\n",
      "---------------------------------------  -------------\n",
      "epoch                                      0\n",
      "replay_buffer/size                       200\n",
      "trainer/num train calls                  100\n",
      "trainer/QF1 Loss                          12.6467\n",
      "trainer/QF2 Loss                          12.6645\n",
      "trainer/Policy Loss                       -4.01682\n",
      "trainer/Q1 Predictions Mean                0.00151907\n",
      "trainer/Q1 Predictions Std                 0.00234598\n",
      "trainer/Q1 Predictions Max                 0.00528307\n",
      "trainer/Q1 Predictions Min                -0.00219873\n",
      "trainer/Q2 Predictions Mean               -0.00114215\n",
      "trainer/Q2 Predictions Std                 0.00238422\n",
      "trainer/Q2 Predictions Max                 0.00282575\n",
      "trainer/Q2 Predictions Min                -0.00477886\n",
      "trainer/Q Targets Mean                     3.45835\n",
      "trainer/Q Targets Std                      0.83499\n",
      "trainer/Q Targets Max                      4.85817\n",
      "trainer/Q Targets Min                      1.65594\n",
      "trainer/Log Pis Mean                      -4.01834\n",
      "trainer/Log Pis Std                        0.408936\n",
      "trainer/Log Pis Max                       -3.12835\n",
      "trainer/Log Pis Min                       -4.5947\n",
      "trainer/policy/mean Mean                  -0.000510951\n",
      "trainer/policy/mean Std                    0.00109969\n",
      "trainer/policy/mean Max                    0.0025644\n",
      "trainer/policy/mean Min                   -0.0033341\n",
      "trainer/policy/normal/std Mean             1.00007\n",
      "trainer/policy/normal/std Std              0.00128192\n",
      "trainer/policy/normal/std Max              1.00377\n",
      "trainer/policy/normal/std Min              0.996594\n",
      "trainer/policy/normal/log_std Mean         6.73569e-05\n",
      "trainer/policy/normal/log_std Std          0.00128197\n",
      "trainer/policy/normal/log_std Max          0.00376492\n",
      "trainer/policy/normal/log_std Min         -0.0034121\n",
      "trainer/Alpha                              1\n",
      "trainer/Alpha Loss                        -0\n",
      "expl/num steps total                     200\n",
      "expl/num paths total                       2\n",
      "expl/path length Mean                    100\n",
      "expl/path length Std                       0\n",
      "expl/path length Max                     100\n",
      "expl/path length Min                     100\n",
      "expl/Rewards Mean                         -0.593206\n",
      "expl/Rewards Std                           0.722925\n",
      "expl/Rewards Max                           1.36489\n",
      "expl/Rewards Min                          -2.13511\n",
      "expl/Returns Mean                        -59.3206\n",
      "expl/Returns Std                           0\n",
      "expl/Returns Max                         -59.3206\n",
      "expl/Returns Min                         -59.3206\n",
      "expl/Actions Mean                         -0.0274913\n",
      "expl/Actions Std                           0.627095\n",
      "expl/Actions Max                           0.99717\n",
      "expl/Actions Min                          -0.996509\n",
      "expl/Num Paths                             1\n",
      "expl/Average Returns                     -59.3206\n",
      "expl/env_infos/final/reward_run Mean      -1.18585\n",
      "expl/env_infos/final/reward_run Std        0\n",
      "expl/env_infos/final/reward_run Max       -1.18585\n",
      "expl/env_infos/final/reward_run Min       -1.18585\n",
      "expl/env_infos/initial/reward_run Mean     0.348732\n",
      "expl/env_infos/initial/reward_run Std      0\n",
      "expl/env_infos/initial/reward_run Max      0.348732\n",
      "expl/env_infos/initial/reward_run Min      0.348732\n",
      "expl/env_infos/reward_run Mean            -0.356803\n",
      "expl/env_infos/reward_run Std              0.730368\n",
      "expl/env_infos/reward_run Max              1.43517\n",
      "expl/env_infos/reward_run Min             -1.91547\n",
      "expl/env_infos/final/reward_ctrl Mean     -0.179273\n",
      "expl/env_infos/final/reward_ctrl Std       0\n",
      "expl/env_infos/final/reward_ctrl Max      -0.179273\n",
      "expl/env_infos/final/reward_ctrl Min      -0.179273\n",
      "expl/env_infos/initial/reward_ctrl Mean   -0.191614\n",
      "expl/env_infos/initial/reward_ctrl Std     0\n",
      "expl/env_infos/initial/reward_ctrl Max    -0.191614\n",
      "expl/env_infos/initial/reward_ctrl Min    -0.191614\n",
      "expl/env_infos/reward_ctrl Mean           -0.236402\n",
      "expl/env_infos/reward_ctrl Std             0.0715917\n",
      "expl/env_infos/reward_ctrl Max            -0.0664812\n",
      "expl/env_infos/reward_ctrl Min            -0.422613\n",
      "eval/num steps total                       0\n",
      "eval/num paths total                       0\n",
      "time/data storing (s)                      0.000276002\n",
      "time/evaluation sampling (s)               0.710884\n",
      "time/exploration sampling (s)              0.0717769\n",
      "time/logging (s)                           0.00112544\n",
      "time/sac training (s)                      0.530838\n",
      "time/saving (s)                            0.00300013\n",
      "time/training (s)                          1.861e-05\n",
      "time/epoch (s)                             1.31792\n",
      "time/total (s)                             3.1772\n",
      "Epoch                                      0\n",
      "---------------------------------------  -------------\n"
     ]
    }
   ],
   "source": [
    "from gym.envs.mujoco import HalfCheetahEnv\n",
    "from gym.envs.box2d import CarRacing\n",
    "\n",
    "import rlkit.torch.pytorch_util as ptu\n",
    "from rlkit.data_management.env_replay_buffer import EnvReplayBuffer\n",
    "from rlkit.envs.wrappers import NormalizedBoxEnv\n",
    "from rlkit.launchers.launcher_util import setup_logger\n",
    "from rlkit.samplers.data_collector import MdpPathCollector\n",
    "from rlkit.torch.sac.policies import (\n",
    "    TanhGaussianPolicy,\n",
    "    MakeDeterministic,\n",
    "    TanhCNNGaussianPolicy,\n",
    "    GaussianCNNPolicy,\n",
    ")\n",
    "from rlkit.torch.sac.sac import SACTrainer\n",
    "from rlkit.torch.networks import ConcatMlp, PretrainedCNN, CNN\n",
    "from rlkit.torch.torch_rl_algorithm import TorchBatchRLAlgorithm\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "ptu.set_gpu_mode(True)\n",
    "\n",
    "def experiment(variant):\n",
    "    expl_env = NormalizedBoxEnv(HalfCheetahEnv())\n",
    "    eval_env = NormalizedBoxEnv(HalfCheetahEnv())\n",
    "    obs_dim = expl_env.observation_space.low.size\n",
    "    action_dim = eval_env.action_space.low.size\n",
    "\n",
    "    M = variant[\"layer_size\"]\n",
    "    qf1 = ConcatMlp(\n",
    "        input_size=obs_dim + action_dim, output_size=1, hidden_sizes=[M, M],\n",
    "    )\n",
    "    qf2 = ConcatMlp(\n",
    "        input_size=obs_dim + action_dim, output_size=1, hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_qf1 = ConcatMlp(\n",
    "        input_size=obs_dim + action_dim, output_size=1, hidden_sizes=[M, M],\n",
    "    )\n",
    "    target_qf2 = ConcatMlp(\n",
    "        input_size=obs_dim + action_dim, output_size=1, hidden_sizes=[M, M],\n",
    "    )\n",
    "    policy = TanhGaussianPolicy(\n",
    "        obs_dim=obs_dim, action_dim=action_dim, hidden_sizes=[M, M],\n",
    "    )\n",
    "    eval_policy = MakeDeterministic(policy)\n",
    "    eval_path_collector = MdpPathCollector(eval_env, eval_policy,)\n",
    "    expl_path_collector = MdpPathCollector(expl_env, policy,)\n",
    "    replay_buffer = EnvReplayBuffer(variant[\"replay_buffer_size\"], expl_env,)\n",
    "    trainer = SACTrainer(\n",
    "        env=eval_env,\n",
    "        policy=policy,\n",
    "        qf1=qf1,\n",
    "        qf2=qf2,\n",
    "        target_qf1=target_qf1,\n",
    "        target_qf2=target_qf2,\n",
    "        **variant[\"trainer_kwargs\"]\n",
    "    )\n",
    "    algorithm = TorchBatchRLAlgorithm(\n",
    "        trainer=trainer,\n",
    "        exploration_env=expl_env,\n",
    "        evaluation_env=eval_env,\n",
    "        exploration_data_collector=expl_path_collector,\n",
    "        evaluation_data_collector=eval_path_collector,\n",
    "        replay_buffer=replay_buffer,\n",
    "        **variant[\"algorithm_kwargs\"]\n",
    "    )\n",
    "    algorithm.to(ptu.device)\n",
    "    algorithm.train()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # noinspection PyTypeChecker\n",
    "    variant = dict(\n",
    "        algorithm=\"SAC\",\n",
    "        version=\"normal\",\n",
    "        layer_size=256,\n",
    "        replay_buffer_size=int(2e4),\n",
    "        algorithm_kwargs=dict(\n",
    "            num_epochs=1,\n",
    "            num_eval_steps_per_epoch=500,\n",
    "            num_trains_per_train_loop=100,\n",
    "            num_expl_steps_per_train_loop=100,\n",
    "            min_num_steps_before_training=100,\n",
    "            max_path_length=1000,\n",
    "            batch_size=16,\n",
    "        ),\n",
    "        trainer_kwargs=dict(\n",
    "            discount=0.99,\n",
    "            soft_target_tau=5e-3,\n",
    "            target_update_period=1,\n",
    "            policy_lr=3e-4,\n",
    "            qf_lr=3e-4,\n",
    "            reward_scale=1,\n",
    "            use_automatic_entropy_tuning=True,\n",
    "        ),\n",
    "    )\n",
    "    setup_logger(\"name-of-experiment\", variant=variant)\n",
    "    ptu.set_gpu_mode(True)  # optionally set the GPU (default=False)\n",
    "    experiment(variant)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_env = NormalizedBoxEnv(HalfCheetahEnv())\n",
    "eval_env = NormalizedBoxEnv(HalfCheetahEnv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf\n",
       " -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf], (17,), float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl_env.observation_space.low.size"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2ee5f948bc78ce492cab358718a01d29a66cdf863cb0bafb6928cda36540681"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
